{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssharma-ss/ss-tools/blob/main/report_to_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b29ziN4vNXPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a40d94-fc36-4120-ff2e-39ff3673f006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# Imports utilities and packages\n",
        "import warnings\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Telling function to ignore all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "def dataReport_to_csv(filename):\n",
        "\n",
        "  # Import file from side column while preserving data\n",
        "  # For future: Modify this to read CSVs in case clients send us CSV,\n",
        "  # Check if the filename contains CSV__ in front\n",
        "  df = pd.read_excel(filename, 'Request Shipping Labels', header=None)\n",
        "\n",
        "  # Remove unnecessary columns after 'REQUEST SHIPPING LABELS'\n",
        "  df = df.loc[:, :11]\n",
        "  po_num = df[3][1]\n",
        "  vendor_dir = df[0][1]\n",
        "  retailer_name = df[1][1]\n",
        "  df = df.drop(df.columns[[4, 6, 7, 8]], axis=1)\n",
        "  new_header = df.iloc[0]\n",
        "  df = df[1:]\n",
        "  df.columns = new_header\n",
        "\n",
        "  # Remove the summary lines from the file.\n",
        "  rem = \"SUMMARY\"\n",
        "  df = df[~df['PO NUM'].str.contains(rem)]\n",
        "\n",
        "  # Remove rows that contain Quantity Shipped = 0\n",
        "  # Otherwise it breaks on portal app\n",
        "  df = df[df['QTY SHIPPED'] != 0]\n",
        "\n",
        "  ##############################################################################\n",
        "  # Remove Nan from the carton number and replace with 6 JUST FOR TESTING\n",
        "  df['SHIP CARTON NUMBER'].fillna('6', inplace=True)\n",
        "  ##############################################################################\n",
        "\n",
        "  # Add placeholder for all the BOL/Tracking field\n",
        "  df['TRACKING'] = \"PLACEHOLDER\"\n",
        "\n",
        "  # Set the headers to the right CSV mapping\n",
        "  df.rename(columns={\n",
        "      'VENDOR'              :  'vendor.tp_directory',\n",
        "      'RETAILER'            :  'retailer.tp_name',\n",
        "      'SHIP TO LOC'         :  'ship_info.ship_to_location.tp_location_code',\n",
        "      'PO NUM'              :  'po.po_num',\n",
        "      'MARK FOR LOC'        :  'po.mark_for_location.tp_location_code',\n",
        "      'GTIN/UPC'            :  'po.ship_carton.po_item_pack.po_item.product.product_gtin',\n",
        "      'QTY SHIPPED'         :  'po.ship_carton.po_item_pack.po_item_pack_qty',\n",
        "      'SHIP CARTON NUMBER'  :  'po.ship_carton.ship_carton_number',\n",
        "      'TRACKING'            :  'ship_info.ship_info_tracking'\n",
        "    }, inplace=True)\n",
        "\n",
        "  # Create file name variables for the format: DATE_PONUM_VENDOR_RETAILER.CSV\n",
        "  file_name_breaks = [\n",
        "      datetime.today().strftime('%Y-%m-%d'),\n",
        "      # df[3].values[0],\n",
        "      # df[0].values[0].title(),\n",
        "      # df[1].values[0].title()\n",
        "    ]\n",
        "  file_name = ''\n",
        "  for i in file_name_breaks:\n",
        "    file_name = file_name + i + \"_\"\n",
        "  file_name = po_num + vendor_dir + retailer_name + \"_CSV_Shipment_Upload\" \".csv\"\n",
        "\n",
        "  # Spit out the CSV file\n",
        "  with open(file_name, 'w') as csv_file:\n",
        "      df.to_csv(index=False, path_or_buf=csv_file)\n",
        "\n",
        "'''\n",
        "\n",
        "  Use cases to check:\n",
        "  1. Whether the file provided is an Excel file or the CSV file\n",
        "  2. Make sure the script doesn't run the CSV's that it produced\n",
        "    -- Solution: Since I append CSV__ in fron the file which is kindof\n",
        "    like a unique identifier.\n",
        "    Look for the first five characters for the filename so that\n",
        "    it tells you that the file was generated\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# @title\n",
        "directory_path = '/content/'\n",
        "directory_files = os.listdir(directory_path)\n",
        "files_to_process = []\n",
        "for f in directory_files:\n",
        "  if f[-4:] == \"xlsx\" or f[-3:] == \"csv\" and f[0:5] != \"CSV__\":\n",
        "    files_to_process.append(f)\n",
        "\n",
        "for f in files_to_process:\n",
        "  dataReport_to_csv(f)\n",
        "\n",
        "print(\"Finished processing\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zq1l1FgOGHU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}